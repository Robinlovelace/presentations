---
title: "AnÃ¡lisis de datos de transporte con R"
subtitle: ' ðŸš²ðŸšƒðŸš€<br/>Workshop'
author: "Robin Lovelace"
date: 'University of Leeds, `r Sys.Date()`<br/><img class="img-footer" alt="" src="http://www.stephanehess.me.uk/images/picture3.png">'
output:
  xaringan::moon_reader:
    # css: ["default", "its.css"]
    # chakra: libs/remark-latest.min.js
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
bibliography: ../references.bib
---

background-image: url(https://c1.staticflickr.com/2/1216/1096671706_571a263b63_b.jpg)
background-position: 50% 50%
class: center, bottom, inverse

# Credit: Mandeep Lota via [flickr](https://www.flickr.com/photos/deepster2k/1096671706)

```{r setup, include=FALSE}
file.copy("../references.bib", ".")
options(htmltools.dir.version = FALSE)
library(RefManageR)
BibOptions(check.entries = FALSE, 
           bib.style = "authoryear", 
           cite.style = 'alphabetic', 
           style = "markdown",
           first.inits = FALSE,
           hyperlink = FALSE, 
           dashed = FALSE)
my_bib = ReadBib("references.bib", check = FALSE)
```

---

# Introduction

- A bit about me + research:

- From rural [Herefordshire](https://www.openstreetmap.org/search?query=herefordshire#map=10/52.1116/-2.7397)

--

- Geographer (BSc 2008) and Environmental Scientist (MSc 2009) by training
- Interest in energy led to PhD in transport (PhD in energy costs of commuting [2014](http://etheses.whiterose.ac.uk/5027/))
- Limitations of [GUIs](https://twitter.com/robinlovelace/status/1129404652150243329) for modelling -> Spatial Microsimulation with R ([2016](https://spatial-microsim-book.robinlovelace.net/))
- Co-authored Efficient R Programming ([2016](https://csgillespie.github.io/efficientR/))
- Lead Developer of Propensity to Cycle Tool (PCT) ([2017](https://www.jtlu.org/index.php/jtlu/article/view/862))
- Application of methods, e.g. to school accessibility ([2018](http://eprints.whiterose.ac.uk/121439/))
- Co-author of Geocomputation with R ([2019](http://geocompr.robinlovelace.net/transport.html))

---

## Example: GPS trace from yesterday

```{r}
u = "https://www.openstreetmap.org/trace/2992569/data"
download.file(u, "track.gpx")
sf::st_layers("track.gpx")
```

---

## Reading-in geographic data

```{r}
track = sf::read_sf("track.gpx", layer = "track_points")
mapview::mapview(track)
```

---

## Data science and the tidyverse

- Inspired by Introduction to data science with R (available free [online](http://r4ds.had.co.nz/)) `r Citep(my_bib, "grolemund_r_2016", .opts = list(cite.style = "authoryear"))`


```{r tds-cover, echo=FALSE, out.width="30%"}
knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/b88ef926a004b0fce72b2526b0b5c4413666a4cb/24a30/cover.png")
```

---

## Transport software: growth of open source

```{r, echo=FALSE, message=FALSE, warning=FALSE}
file.copy("../transport-software.csv", ".")
tms = readr::read_csv("transport-software.csv")[1:5]
tms = dplyr::arrange(tms, dplyr::desc(Citations))
knitr::kable(tms, booktabs = TRUE, caption = "Sample of transport modelling software in use by practitioners. Note: citation counts based on searches for company/developer name, the product name and 'transport'. Data source: Google Scholar searches, October 2018.", format = "html")
```

---

# New ways of getting support

- [gis.stackexchange.com](https://gis.stackexchange.com/questions) has 21,314 questions 

- [r-sig-geo](http://r-sig-geo.2731867.n2.nabble.com/) has 1000s of posts

- RStudio's Discourse community has 65,000+ posts already!

- No transport equivalent (e.g. earthscience.stackexchange.com is in beta)

- Potential for a Discourse forum or similar: transport is not (just) GIS

---

## The Propensity to Cycle Tool

See www.pct.bike

![](https://raw.githubusercontent.com/npct/pct-team/master/figures/front-page-leeds-pct-demo.png)

- I
---

## How is R used in the PCT?

- It's an open source online system for transport planningIt's all reproducible, e.gallowing use in other countriesFind short in which more people drive than cycle

## ---

Stage 1: get data from web

```{r, eval=FALSE, echo=FALSE}
# Aim: get top 1000 lines in repo
library(dplyr)
library(sf)
desire_lines_all = pct::get_pct_lines(region = "isle-of-wight")
desire_lines = desire_lines_all %>% 
  top_n(1000, all)
write_sf(desire_lines, "desire_lines.geojson")
piggyback::pb_upload("desire_lines.geojson")
```


```{r, message=FALSE}
# Set-up, after installing pct and checking out www.pct.bike:
library(dplyr)
library(sf)
desire_lines_all = pct::get_pct_lines(region = "isle-of-wight") %>% 
  top_n(n = 1000, wt = all)
```

---

## Stage II: Geographic data analysis

- Interested only in top 200 lines

```{r}
desire_lines = desire_lines_all %>% 
  top_n(n = 20, wt = all)
```


---

## Stage III: Visualising (polution) data

<!-- A fundamental part of data science is being able to understand your data. -->

<!-- That requires visualisation, R is great for that: -->

```{r, warning=FALSE, eval=FALSE, echo=FALSE}
.pull-left[
plot(desire_lines)
]
.pull-right[
]
```


<!-- - Interactively: -->

```{r, message=FALSE}
library(tmap)
tmap_mode("view")
tm_shape(desire_lines) +
  tm_lines("bicycle", lwd = "all", scale = 5) +
  tm_basemap(server = leaflet::providers$OpenStreetMap.BlackAndWhite)
```


---

## Stage IV: Origin-destination data analysis

- Now we have data in our computer, and verified it works, we can use it

- Which places are most car dependent? 

```{r}
car_dependent_routes = desire_lines %>% 
  mutate(percent_drive = car_driver / all * 100) %>% 
  filter(rf_dist_km < 3 & rf_dist_km > 1) 
```

- Get routes

```{r, message=FALSE, eval=FALSE}
routes = stplanr::line2route(car_dependent_routes)
car_dependent_routes$geometry = routes$geometry
```

```{r, echo=FALSE, eval=FALSE}
# sf::write_sf(car_dependent_routes, "car_dependent_routes.geojson")
# piggyback::pb_upload("car_dependent_routes.geojson")
# piggyback::pb_download_url("car_dependent_routes.geojson")
```

```{r, echo=FALSE}
# car_dependent_routes = sf::read_sf("https://github.com/ITSLeeds/TDS/releases/download/0.2/car_dependent_routes.geojson")
```

---

## Communicating results

Visualisation is vital

```{r, message=FALSE, warning=FALSE, eval=FALSE}
b = c(0, 25, 50, 75)
tm_shape(car_dependent_routes) +
  tm_lines(col = "percent_drive", lwd = "all", scale = 5, breaks = b, palette = "-inferno")
```

---

## Upcoming

- 11:00 - 12:00: Getting and analysing spatio-temporal transport: examples with `stats19`, `pct` and `osmdata` packages

12:00 - 12:30: Break

- 12:30 - 13:00: Origin-destination (OD) data analysis with `stplanr`

- 13:00 - 14:00: From routes to route networks and data and methods for assessing cycling potential

--

- Any questions?

--

- Everyone happy with RStudio?

---


## R basics

Course home: http://git.io/tds4hr

```{r, eval=FALSE}
x = 1:5
y = c(0,1,3,9,18)
plot(x, y)
```

---

## Data frames

```{r, eval=FALSE}
cat = data.frame(name = c("Tiddles", "Chester", "Shadow"),
                  type = c("Tabby", "Persian", "Siamese"),
                   age = c(1, 3, 5),
                  likes_milk = c(TRUE, FALSE,TRUE))
even_numbers = seq(from = 2, to = 4000, by = 2)
random_letters = sample(letters, size = 100, replace = TRUE)
small_matrix = matrix(1:24, nrow = 12)
```


## Test code

- Test code I sent

```{r, eval=FALSE}
# set-up
library(osmdata)
library(tmap)
ttm()

# get data
d = opq("madrid") %>% 
  add_osm_feature("highway", "cycleway") %>% 
  osmdata_sf()
```

---

## Practice code

```{r}
library(stplanr)
library(tidyverse)
l = flowlines_sf %>% 
  mutate(percent_walk = On.foot / All)
plot(l["percent_walk"])
```

---

## Spatial data in R

- Most transport data is spatial

- In the package `sf` it's just data frames

- See Chapter 4 of Geocomputation with R: https://geocompr.robinlovelace.net/spatial-operations.html

- See sections 1 to 3 in the exercises: https://git.io/tds2dayex

```{r}
iow = pct::get_pct_zones("isle-of-wight")[1:9]
class(iow)
names(iow)
iow[1:2, c(1, 5, 6, 7, 8)]
```


---

# Getting and analysing spatio-temporal transport data

---


## Data access in context

--

- Data cleaning (or 'tidying' or 'wrangling') is part of a wider process 
`r Citep(my_bib, "grolemund_r_2016", .opts = list(cite.style = "authoryear"))`

```{r, echo=FALSE}
knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/795c039ba2520455d833b4034befc8cf360a70ba/558a5/diagrams/data-science-explore.png")
```

--

- It's important to have an idea where you're heading with the analysis

--

- Often best to start with pen and paper

---

## Data access/cleaning vs modelling time

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Tapson&#39;s Rules of Machine Learning:<br>4. Time spent on data cleaning is an order of magnitude more productive than time spent on hyperparameter tuning.<br><br>(Extreme example: achieved a Top 10 result in Kaggle using linear regression, as the only team that cleaned 50/60Hz noise first.)</p>&mdash; Jonathan Tapson (@jontapson) <a href="https://twitter.com/jontapson/status/1103024752019402753?ref_src=twsrc%5Etfw">March 5, 2019</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Source: https://twitter.com/jontapson/status/1103024752019402753


---

background-image: url()
background-size: cover
class: center, middle

# A typology of data sources

---

## Information and data pyramids

Data science is climbing the DIKW pyramid

```{r, echo=FALSE}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/DIKW_Pyramid.svg/220px-DIKW_Pyramid.svg.png")
```


---

## A geographic availability pyramid

- Recommendations
- Build this here!

- City-specific datasets
  - Bristol cycle count data

- Hard-to-access national data

- Open international/national datasets
  - Open origin-destination data from UK Census

- Globally available, low-grade data (bottom)
  - OpenStreetMap, Elevation data

---

## An ease-of access pyramid

- Data provision packages
  - Use the pct package
  - stats19 package

- Pre-processed data
  - E.g. downloading data from website www.pct.bike

- Messy official data
  - Raw STATS19 data

---

## A geographic level of detail pyramid

- Agents
- Route networks
- Nodes
- Routes
- Desire lines
- Transport zones


---

## Observations

- Official sources are often smaller in sizes but higher in Quality

- Unofficial sources provide higher volumes but tend to be noisy, e.g.: https://onlinelibrary.wiley.com/doi/full/10.1111/gean.12081

- Another way to classify data is by quality: signal/noise ratios

- Globally available datasets would be at the bottom of this pyramid; local surveys at the top.

Source: https://geocompr.robinlovelace.net/read-write.html


- Which would be best to inform policy?

---

## Portals

- UK geoportal, providing geographic data at many levels: https://geoportal.statistics.gov.uk
- Other national geoportals exist, such as this: http://www.geoportal.org/
- A good source of cleaned origin destination data is the Region downloads tab in the Propensity to Cycle Tool - see the Region data tab for West Yorkshire here, for example: http://www.pct.bike/m/?r=west-yorkshire
- OpenStreetMap is an excellent source of geographic data with global coverage. You can download data on specific queries (e.g. highway=cycleway) from the overpass-turbo service: https://overpass-turbo.eu/ or with the **osmdata** package

---

## Online lists

For other datasets, search online! Good starting points in your research may be:

- The open data section in Geocomputation with R - https://geocompr.robinlovelace.net/read-write.html#retrieving-data
- Transport datasets mentioned here: https://data.world/datasets/transportation
- UK government transport data: https://ckan.publishing.service.gov.uk/publisher/department-for-transport

---

## Data packages

- The **openrouteservice** github package provides routing data
- The stats19 package can get road crash data for anywhere in Great Britain [@lovelace_stats19_2019] see here for info: https://itsleeds.github.io/stats19/
- The pct package provides access to data in the PCT: https://github.com/ITSLeeds/pct
- There are many other R packages to help access data

---

# Example: stats19 data

- An R package for getting and cleaning UK road crash data

- See the package website at: https://itsleeds.github.io/stats19/

- Example code:

```{r, eval=FALSE}
library(stats19)
crashes = get_stats19(year = 2017, type = "accident", ask = FALSE)
```


---

# Practical

- Work through the following exercises (i:

- Sion 1):
: to re-cap vital R/Studio skills
- Section 2: for information about packages, especially sf/ggplot2
- Section 3: on working with spatial data
- Section 4: on geographic data visualisation
- Section 5: one downloading/analysing spatial data
- Section 6: origin-destination datatt- 

p://git.io/tds2dayex



---

# stats19 data analysis 

- See [itsleeds.github.io/stats19](https://itsleeds.github.io/stats19/)

--

Basics of STATS19 data

- Spatial *and* temporal attributes allow subsetting
- Spatial resolution: ~10 metres
- Temporal resolution: ~10 minutes

---

## stats19 exercises 

1. Download and plot all crashes reported in Great Britain in 2017 (hint: see [the stats19 vignette](https://cran.r-project.org/web/packages/stats19/vignettes/stats19.html))
1. Find the function in the `stats19` package that converts a `data.frame` object into an `sf` data frame. Use this function to convert the road crashes into an `sf` object, called `crashes_sf`, for example.
1. Filter crashes that happened in the Isle of Wight based on attribute data (hint: the relevant column contains the word `local`)
1. Filter crashes happened in the Isle of Wight using geographic subsetting (hint: remember `st_crs()`?)
1. Bonus: Which type of subsetting yielded more results and why? 
1. Bonus: how many crashes happened in each zone?
1. Create a new column called `month` in the crash data using the function `lubridate::month()` and the `date` column.
1. Create an object called `a_iow_may` representing all the crashes that happened in the Isle of Wight in the month of May
1. Bonus: Calculate the average (`mean`) speed limit associated with each crash that happened in May across the zones of the Isle of Wight (the result is shown in the map)

---

## Speed crashes in the IoW in May

```{r, echo=FALSE, results='hide', message=FALSE}
library(stats19)
library(dplyr)
library(sf)
a = get_stats19(2017, "ac", ask = FALSE)
asf = format_sf(a)
a_iow = asf %>% 
  filter(local_authority_district == "Isle of Wight")
nrow(a_iow)
iow = pct::get_pct_zones(region = "isle-of-wight")
iow_osbg = st_transform(iow, 27700)
a_iow_sf = a_iow[iow_osbg, ]
nrow(a_iow_sf)
# mapview::mapview(iow) +
#   mapview::mapview(a_iow)
class(a$date)
class(a$time)
a_iow$month = lubridate::month(a_iow$date)
a_iow_may = a_iow %>% 
  filter(month == 5)
a_agg = aggregate(a_iow_may["speed_limit"], iow_osbg, mean)
plot(a_agg)
```



---

# OD data with stplanr

- See [ropensci.github.io/stplanr](https://ropensci.github.io/stplanr/)

---

# Local route network analysis

- See [itsleeds.github.io/opentripplanner](https://itsleeds.github.io/opentripplanner/)

---

# Data and methods for assessing cycling potential

- See [itsleeds.github.io/pct](https://itsleeds.github.io/pct/)


- And https://geocompr.robinlovelace.net/transport.html

---

# References

```{r, 'refs', results="asis", echo=FALSE}
PrintBibliography(my_bib)
# RefManageR::WriteBib(my_bib, "refs-geostat.bib")
```
